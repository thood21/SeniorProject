# Annotated Bibliography
Before beginning this project, I sought out sources that did similar projects, used similar methodologies, or used similar hardware. The purpose of this is to aggregate information from disparate sources to synthesize a blend of information into a single source to serve as a guide for future users.

1. _Aloufi, Ranya, Hamed Haddadi and David Boyle. "Emotion Filtering at the Edge." Association for Computing Machinery (2019): 1-6. Digital Article._
    * This article outlines the implementation and evaluation of emotion filtering using a Raspberry Pi 4. Because the Raspberry Pi is used as a sensor to collect data and also analyze it, it is an edge analytics device. Edge analytics has gained immense popularity recently, fueling a wave of real-time analytics as devices are able to now sensor/poll external stimuli and immediately analyze it and output results or reactions. Filtering human emotions at the edge involves devices that are able to detect changes on hosts and analyze minute changes and chain these changes together into an ultimately change in emotion. Small actions such as wrinkles around the mouth, angling of eye brows, open eye width, voice pitch, decible levels, and hesitation are a few of the many changes used to diagnose emotion. In the pursuit of creating AI, human emotion detection is a necessity, making this research an important cornerstone. Finally, this article shows that performance accuracy is not hindered by edge analytics when compared to more powerful cloud-based approaches. Traditional systems stream data back from sensors and analyze data in the cloud, which is less efficient and sometimes slower. In essence, this article demonstrates the capabilities and accuracy of edge analytics, while also pressing forward by making advances for human emotion detection. 
    
2. _Antonini, Mattia, et al. "Resource Characterisation of Personal-Scale Sensing Models on Edge Accelerators." Association for Computing Machinery (2019): 49-55. Digital Article._
    * Edge acceleration is a new class of cutting edge purpose-built or job-specific System on a Chip (SoC) for running deep learning models efficientl on edge devices. The accelerators offer a plethora of benefits such as ultra-low latency, sensitive data protection via cryptography, and extreme data availability via locality. Edge accelerators are creating opportunities for builing real-time sensory systems in the real world, and leading scientists to rethink traditional and existing solutions for IoT, wearables, and other sensory devices. This article examines the performance of a set of edge accelerators in running scaled sensory deep learning models, benchmarking a total of 8 unique models with varying architectures and tasks (motion, audio, vision) across seven platform configurations with three distinct accelerators including the Google Coral (our device), Nvidia Jetson Nano, and Intel Neural Compute Stick. The article then reports on the execution performance concerning metrics such as latency, memory usage, and power consumption while discussing the workflows and respective limitations.
    
3. _Coral. "Dev Board Datasheet." January 2020. Coral AI Docs. System Report. January 2020._
    * The datasheet outlines component specifications, capabilities, and potential use cases. The Coral Dev Board is a single-board computer that's ideal for performing fast machine learning (ML) inferencing in a small form factor. Like other boards, it's widely used for edge analytics and real-time data crunching, and can be used to prototype various embedded system and then scale to production using the on-board Coral System-on-Module (SoM) combined with any number of custom PCB hardware. The module itself provides a fully-integrated system including: an iMX 8M chip, eMMC memorym LPDDR4 RAM, Bluetooth, and Wi-Fi. However, the biggest draw to this system is the specialized Google "Edge TPU coprocessor," a small ASIC engineered by Google for extreme performance ML inferencing with power power consumption (energy efficient). The SoM provides a fully-integrated system, including NXP's iMX 8M system-on-chip (SoC), eMMC memory, LPDDR4 RAM, Wi-Fi, and Bluetooth, but its unique power comes from Google's Edge TPU coprocessor. The Edge TPU is a small ASIC designed by Google that provides high performance ML inferencing with a low power cost. On the board itself there is a healthy endowment of I/O such as: USB 2.0/3.0 ports, DSI display interface, CSI-2 camera interface, Ethernet port, speaker terminals, and a 40-pin I/O header. The key benefits of this device are as follows: complete Linux system (Mendel, derivative of Debian), prototyping capabilities, and high-speed and energy efficient ML inferencing.
    
4. _Ding, Changxing and Dacheng Tao. "A Comprehensive Survey on Pose-Invariant Face Recognition." Association for Computing Machinery (2016): Article 37. Digital Article._
    * This article studies facial recognition with unchanging (invariant) poses; this translates to analyzing still images of human faces. This type of human facial recognition is useful in certain applications such as facial biometrics recognition, but useless in others such as real-time facial recognition. Pose invariant facial recognition (PIFR) is typically grouped into four distinct categories: pose-robust feature extraction approaches, multiview subspace learning approaches, face synthesis approaches, and hybrid approaches. This article discusses the motivations, strategies, pros/cons, and performance of representative approaches and details directions for future research. Ultimately, the capacity to recognize faces under varied poses is a fundamental human ability that presents a unique challenge for computer vision systems, which spurred this group of researches to delve into a separate area of study - PIFR. 

5. _Kejariwal, Arun, Sanjeev Kulkarni and Karthik Ramasamy. "Real Time Analytics: Algorithms and Systems." Association for Computing Machinery (2015): 2040â€“2041. Digital Article._
    *  This article outlines example use cases of streaming analytics and notes how it powers a lot of the everyday functions we do/use. Business metrics, healthcare reports, e-commerce tracking, telecommunications, government services, and more all utilize streaming analytics. This article also presents a various applications, algorithms, and platforms for streaming analytics, as well as the evolution of the field and current challenges. Common challenges include turnover time between capture data and presenting it in analytics, efficiently handling and streaming massive amounts of data ("Big Data"), maintaining data quality standards, and making use of data you collect (otherwise, why waste resources storing useless data). In essence, the article examines the implications and effects of the "3 V's" of daya analytics - Velocity/Veracity, Volume, and Variety.

6. _Shotton, Jamie, et al. "Real-Time Human Pose Recognition in Parts from Single Depth Images." Association for Computing Machinery (2013): 116-124. Digital Article._
    * This article outlines research methods used to report real-time human pose recognition via prediction from 3D positioning of body parts and joints obtained from single depth images. While this methodology discussed is strongly remeniscent of current object recognition strategies, it does differentiate itself by utilizing an algorithm that does not depend on information from preceding image frame data. The proposed methodology breaks down images into recognizable body parts and then further into pixels, enabling per-pixel machine learning techniques to efficiently analyze data. The algorithm is able to estimate body part labels invariant to pose, body shape, clothing, and other irrelevancies. The proposed system runs in uner 5ms on the Xbox 360 (system configuration used for specific benchmarking purposes). 
